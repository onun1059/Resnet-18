{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNQGPiDYNZcAJ+XCE/iX9eM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/onun1059/Resnet-18/blob/main/%EC%A2%85%EC%84%A4%EA%B8%B0%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN 모델에서 튜닝 가능한 하이퍼파라미터\n",
        "* Convolutional layers: 필터의 갯수, 필터의 크기, stride값, zero-padding의 유무\n",
        "* Pooling layers: Pooling방식 선택(MaxPool or AvgPool), Pool의 크기, Pool stride 값(overlapping)\n",
        "* Fully-connected layers: 넓이(width)\n",
        "* 활성함수(Activation function): ReLU(가장 주로 사용되는 함수), SoftMax(multi class classification), Sigmoid(binary classification)\n",
        "* Loss function: Cross-entropy for classification, L1 or L2 for regression\n",
        "* 최적화(Optimization) 알고리즘과 이것에 대한 hyperparameter(보통 learning rate): SGD(Stochastic gradient descent), SGD with momentum, AdaGrad, RMSprop\n",
        "* Random initialization: Gaussian or uniform, Scaling\n",
        "* https://halfundecided.medium.com/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-cnn-convolutional-neural-networks-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-836869f88375"
      ],
      "metadata": {
        "id": "58En03V2gElz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 구글드라이브와 colab 연동\n",
        "from google.colab import drive  # 구글드라이브와 연동하기 위한 라이브러리\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "NyI37cNqLKgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 라이브러리 import\n",
        "'''\n",
        "pytorch, torchvision, matplotlib, numpy, tqdm, time 라이브러리가 요구된다.\n",
        "'''\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time"
      ],
      "metadata": {
        "id": "dnrcJU7sLKdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 하이퍼 파라미터 설정\n",
        "EPOCH = 5\n",
        "batch_size = 8\n",
        "learning_rate = 1e-3\n",
        "momentum = 0.9"
      ],
      "metadata": {
        "id": "x0jpKuWALKaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. torch에서 사용할 gpu 설정\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'{device} is available')"
      ],
      "metadata": {
        "id": "MpteSvGGLKTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Classification할 Class list 지정\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "rEh12vuwLJ_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 이미지 전처리\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n",
        "    )"
      ],
      "metadata": {
        "id": "axEip7i2OlNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. (수정불필요) Dataset 저장 및 Tensor 형태로 변환\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "h4gR0kAkOlES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Baseline CNN Network\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()  ######zero padding -> 가장자리 손실 사라진다, 정보가 중복되는 overfitting 방지\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)   ##(input_channel, output_channel, kerner_size, stride=1), filter 5여서 32x32->28x28(padding 안 한 상태)\n",
        "    self.pool1 = nn.MaxPool2d(2,2)    ##(kerner = filter, stride = filter 움직임 정도 , stride bigger-> image smaller)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)    ##pooling: correlation이 낮은 부분 삭제-> 결과값 크기 감소 (Max or average)\n",
        "    self.pool2 = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "    self.fc2 = nn.Linear(120, 10) # 클래스 개수 10\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(F.relu(self.conv1(x)))     ## convolution layer = convolution 처리 + Activiation function(relu)\n",
        "    x = self.pool2(F.relu(self.conv2(x)))     ## relu : 선형 함수 convlution에 비선형성 추가\n",
        "\n",
        "    x = x.view(-1, 16 * 5 * 5) # -1 : batchsize\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "ScCPjwe5Ok7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as Fclass Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # max-pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # convolutional layers\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        # flatten and fully connected layers\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZivOGYcvx-9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Network 선언 및 device 위에 올리기\n",
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "VJHmJTF7OkyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. (수정 가능) Loss function으로 사용할 criterion 변수 생성\n",
        "criterion = nn.CrossEntropyLoss()       ## 분류 문제여서 손실함수 크로스 엔트로피 사용"
      ],
      "metadata": {
        "id": "TO_69v8QOkpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)"
      ],
      "metadata": {
        "id": "xoqSwsp2LUAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Training\n",
        "#수정# loss_ = []\n",
        "n = len(trainloader)\n",
        "\n",
        "for epoch in range(EPOCH):\n",
        "\n",
        "  running_loss = 0.0\n",
        "  start = time.time()\n",
        "\n",
        "  #수정# for i, data in tqdm(enumerate(trainloader, 0)):\n",
        "  for data in tqdm(trainloader):\n",
        "\n",
        "    inputs, labels = data[0].to(device), data[1].to(device) # 배치 데이터\n",
        "    optimizer.zero_grad() # 배치마다 optimizer 초기화\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, labels) # 크로스 엔트로피 손실함수 계산\n",
        "\n",
        "    loss.backward() # backpropagation\n",
        "    optimizer.step() # 가중치 최적화\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  # !!주의!! weight 저장경로는 상황에 맞게 수정\n",
        "  torch.save(net.state_dict() ,'/usr/local/lib/python3.10/dist-packages/google/colab/drive.py')\n",
        "\n",
        "  #수정# loss_.append(running_loss / n)\n",
        "  #수정# print('[%d] loss: %.3f' %(epoch + 1, running_loss / len(trainloader)))\n",
        "  print('[%d] loss: %.3f' %(epoch + 1, running_loss / n))\n",
        "  print(\"epoch time :\", time.time()-start)\n"
      ],
      "metadata": {
        "id": "azbVRGKDLT2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "net = Net()\n",
        "net.to(device)\n",
        "# !!주의!! weight 저장경로는 상황에 맞게 수정\n",
        "net.load_state_dict(torch.load('/usr/local/lib/python3.10/dist-packages/google/colab/drive.py'))\n",
        "\n",
        "# (수정불가) Evaluation\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_pred = {classname: 0 for classname in classes}  #dictionary 생성\n",
        "total_pred = {classname: 0 for classname in classes}    #dictionary 생성\n",
        "\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad(): # autograd를 끔으로써 메모리 사용량을 줄이고 연산 속도를 높일 수 있다.\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0) # labels.size = batch_size\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predicted):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
        "                                                   accuracy))"
      ],
      "metadata": {
        "id": "TrIiJgfWO3Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inference\n",
        "def imshow(img):\n",
        "    img = img/2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(20,10))\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "#수정# images, labels = dataiter.next()\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# GroundTruth display\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(8)))\n",
        "\n",
        "# Predicted display\n",
        "net = Net()\n",
        "net.to(device)\n",
        "# !!주의!! weight 저장경로는 상황에 맞게 수정\n",
        "net.load_state_dict(torch.load('/usr/local/lib/python3.10/dist-packages/google/colab/drive.py'))\n",
        "\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(8)))"
      ],
      "metadata": {
        "id": "O3UMcDGqO3DY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}